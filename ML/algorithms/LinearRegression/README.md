# Simple Linear Regression

![6772339_1608277678_simple](https://github.com/avs-abhishek123/Machine-Learning/blob/main/images/sample_images/6772339_1608277678_simple.jpg?raw=true)

<hr style ="border: 10px solid purple; border-radius: 5px;">

| Content | Link |
| :---: | :---: |
| Simple Linear Regression | [My Kaggle Notebook Link](https://www.kaggle.com/code/abhishek14398/simple-linear-regression) |
| Simple Linear Regression Kaggle Notebook | [My Kaggle Notebook Link](https://www.kaggle.com/code/abhishek14398/simple-linear-regression) |
| Linear Regression Gradient Descent |  |
| Linear Regression Normal Equation |  |

We can generate predictions using simple linear regression, a statistical technique for determining the connection between two variables. Typically, the two variables are written as y and x. X stands for the independent variable, or the variable that is utilised to predict the dependent variable. y stands for the dependent variable, often known as the result or output.

A line of best fit, or the regression line, will be generated by a straightforward linear regression model. You might be familiar with the idea of tracing the line of greatest fit through a data scatter plot. Consider a scatter plot that illustrates how years of experience impact earnings. Think of a line you may draw to indicate the pattern.

The simple linear regression equation we'll employ is presented here. The regression line's y-intercept (ùú∑0), or where it will begin on the y-axis, is the constant. The slope and description of the link between the independent and dependent variables are provided by the beta coefficient (ùú∑1). The amount of change in the dependent variable for each change in the independent variable of one unit is represented by the coefficient, which can be either positive or negative.

